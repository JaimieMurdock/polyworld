#!/usr/bin/python

CurrentVersion=2

### Configurable parameters
OutputFilename2='MetricHist.plt'

#CALC_COMPLEXITY_OVER_DIRECTORY="./CalcComplexityOverDirectory.sh"
#### Don't modify anything beneath here unless you know what you're doing
import algorithms
import getopt, glob, string, sys, os
import common_functions
from common_functions import err, warn, list_difference
import common_metric
import datalib
import networkx as nx
import numpy
import datetime

### Now initialize some global variables
##OutputFilename = common_complexity.FILENAME_AVR
OutputFilename = common_metric.FILENAME_AVR
OutputFilenameRandom = common_metric.RANDOMFILENAME_AVR
NUMBINS = common_metric.DEFAULT_NUMBINS
RandomN = 0
DefaultRecent = 'Recent'
LEGACY_MODES = ['force','prefer','off']
LegacyMode = 'off'
####

####################################################################################
###
### main()
###
####################################################################################
def main():
	#check_environment()

	metrics, recent_type, arg_paths = parse_args(sys.argv[1:])

	recent_subpath = os.path.join('brain', recent_type)
	try:
		run_paths = common_functions.find_run_paths(arg_paths,
								recent_subpath)
	except common_functions.InvalidDirError, e:
		show_usage(str(e))

	recent_dirs = map(lambda x: os.path.join(x, recent_subpath),
			  run_paths)

	for recent_dir in recent_dirs:
		analyze_recent_dir(metrics,
				   recent_dir)

	print "Done!"
	return 0

####################################################################################
###
### FUNCTION check_environment()
###
####################################################################################
def check_environment():
	global CALC_COMPLEXITY

	CALC_COMPLEXITY = common_functions.pw_env('complexity')

####################################################################################
###
### FUNCTION parse_args()
###
####################################################################################
def parse_args(argv):
	global NUMBINS, LegacyMode, RandomN

	if len(argv) == 0:
		show_usage()

	metrics = common_metric.DEFAULT_METRICS#'CC' represents clustering coefficient
								  #and 'SP' represents (normalized) shortest path length
								  #and 'CP' represents charateristic path length


	recent_type = DefaultRecent

	short = 'D:V:R:'
	long = []

	try:
		opts, args = getopt.getopt(argv, short, long)
	except getopt.GetoptError, e:
		show_usage(str(e))

	for opt, value in opts:
		opt = opt.strip('-')

		if opt == 'D':
			try:
				recent_type = common_functions.expand_abbreviations( value,
											 common_functions.RECENT_TYPES,
											 case_sensitive = False )
			except common_functions.IllegalAbbreviationError, x:
				err(str(x))
		elif opt == 'V':
			metrics = map(string.upper, value.split(','))
		elif opt == 'R':
			try:
				RandomN = int(value)
				if RandomN < 0:
					show_usage("R argument must be >= 0")
			except:
				show_usage("R argument must be an integer >= 0")
##		elif opt == 'b' or opt == 'bins':
##			try:
##				NUMBINS = int(value)
##			except:
##				show_usage("Invalid integer argument for --bins (%s)" % value)
		else:
			assert(False)

	if len(args) == 0:
		show_usage('Must specify run/run-parent directory.')

	paths = list(args)

	return metrics, recent_type, paths

####################################################################################
###
### analyze_recent_dir()
###
####################################################################################
def analyze_recent_dir(metrics, recent_dir):
	global RandomN
	
	metrics_first = metrics[:]
	
	if RandomN > 0:
		print 'Will calculate random metrics after all actual metrics are calculated'
	
	if 'SW' in metrics:
		print 'Will calculate SW (if needed) after all other actual and random metrics are calculated'
		print "    This causes a recalculation of the other metrics' averages, but not of the metrics themselves"
		metrics_first.remove('SW')

	if 'SC' in metrics:
		print 'Will calculate SC (if needed) after all other actual and random metrics are calculated'
		print "    This causes a recalculation of the other metrics' averages, but not of the metrics themselves"
		metrics_first.remove('SC')

	__analyze_recent_dir(metrics_first, recent_dir, random = False)
	if RandomN > 0:
		__analyze_recent_dir(metrics_first, recent_dir, random = True)

	# This is an awful hack, because all other actual metrics must be
	# re-averaged from the <epoch>/metric_*.plt files to produce the
	# AvrMetric.plt file.  But it's no less time consuming than running
	# the script twice by hand, first for CC, SP, and CP (actual and
	# random), and then running it again for CC, SP, CP, SW and SC.  And
	# unfortunately, the way things are set up, the <epoch>/metric_*.plt
	# files must already be in place for CC and SP before SW can be
	# computed.
	#
	# The right way to do this would be to have any newly calculated
	# metrics be added to the existing AvrMetric.plt file, but that's
	# not how it works at present.  Then this could be called with
	# just ['SW', 'SC'] instead of metrics, and only SW and SC would be computed.

	# There is no Random clause, because this is really only for SW and SC,
	# for which Random graph metrics have no meaning.
	if 'SW' in metrics or 'SC' in metrics:
		__analyze_recent_dir(metrics, recent_dir, random = False)



####################################################################################
###
### __analyze_recent_dir()
###
####################################################################################
def __analyze_recent_dir(metrics, recent_dir, random):
	global RandomN
	
	if random:
		outputpath = os.path.join(recent_dir, OutputFilenameRandom )
	else:
		outputpath = os.path.join(recent_dir, OutputFilename)
						
	
	print "- recent directory='%s'" %(recent_dir)
	print "- output='%s'" % (outputpath)

	#-----------------------------------------------------------------------------------
	#--
	#-- Find epoch/timestep directories
	#--
	#-----------------------------------------------------------------------------------
	timesteps = []
	# list all of the timesteps, make sure they are all integers (and directories), then sort them by number.
	for potential_timestep in os.listdir( recent_dir ):
		if not potential_timestep.isdigit(): continue					# if timestep IS NOT a digit (note, 0 is considered a digit), skip.
		if not os.path.isdir( os.path.join(recent_dir, potential_timestep) ): continue	# if the timestep isn't a directory, skip it.
	
		timesteps.append( int(potential_timestep) )						# add timestep to our list
	
	if len(timesteps) == 0:
		err('No epochs found. Not a valid recent directory.')

	timesteps.sort()									# sort the timesteps, lowest numbers come first.
	
	#-----------------------------------------------------------------------------------
	#--
	#-- Compute complexities for all timesteps
	#--
	#-- (store values to file in timestep dir)
	#--
	#-----------------------------------------------------------------------------------
	DATA={ }
	
	print "Final Timestep: %s" % ( max(timesteps) )
	print datetime.datetime.now()
	print "Processing:",
	for t in timesteps:
		timestep_directory = os.path.join(recent_dir, str(t))
		print '%s...\n' % (t),
		sys.stdout.flush()	
	
		DATA[t] = tdata = {}

		metrics_remaining = metrics

		if len(metrics_remaining) > 0:
			metrics_computed = compute_metrics(metrics_remaining,
							   timestep_directory,
							   tdata,
							   random)
			metrics_remaining = list_difference(metrics_remaining,
								metrics_computed)

		assert(len(metrics_remaining) == 0)

	#-----------------------------------------------------------------------------------
	#--
	#-- Create 'Avr' File
	#--
	#-----------------------------------------------------------------------------------
	AVR = algorithms.avr_table(DATA,
							   metrics,
							   timesteps)
	
	datalib.write(outputpath, AVR)
	
	
##	#-----------------------------------------------------------------------------------
##	#--
##	#-- Create 'Norm' file
##	#--
##	#-----------------------------------------------------------------------------------
##	tables = compute_bins(DATA,
##				  timesteps,
##				  metrics,
##				  AVR,
##				  lambda row: row.get('min'),
##				  lambda row: row.get('max'))
##	
##	outputpath = os.path.join(recent_dir, OutputFilename2.replace( '.', 'Norm.'))
##	
##	datalib.write(outputpath, tables)
##	
##	
##	#-----------------------------------------------------------------------------------
##	#--
##	#-- Create 'Raw' file
##	#--
##	#-----------------------------------------------------------------------------------
##	MAXGLOBAL = dict([(type, float('-inf')) for type in metrics])
##	MINGLOBAL = dict([(type, float('inf')) for type in metrics])
##	
##	for avr_table in AVR.values():
##		for row in avr_table.rows():
##			type = avr_table.name
##	
##			MAXGLOBAL[type] = max(MAXGLOBAL[type], row.get('max'));
##			MINGLOBAL[type] = min(MINGLOBAL[type], row.get('min'));
##	
##	tables = compute_bins(DATA,
##				  timesteps,
##				  metrics,
##				  AVR,
##				  lambda row: MINGLOBAL[row.table.name],
##				  lambda row: MAXGLOBAL[row.table.name])
##	
##	outputpath = os.path.join(recent_dir, OutputFilename2.replace( '.', 'Raw.'))
##	
##	datalib.write(outputpath, tables)
##	

####################################################################################
###
### FUNCTION compute_small_world_index()
###
####################################################################################
def compute_small_world_index(timestep_directory, length_metric):
	def __list_division(a,b):
		assert(len(a) == len(b))
		c = []
		for i in range(len(a)):
			c.append(float(a[i])/float(b[i]))
		return c
	
	# Check if all needed data is available
	metric_files = glob.glob(os.path.join(timestep_directory, "*.plt"))
	if length_metric == 'SP':
		sw_metric_files = ['metric_CC.plt','metric_CC_Random.plt','metric_SP.plt','metric_SP_Random.plt']
	else:
		sw_metric_files = ['metric_CC.plt','metric_CC_Random.plt','metric_CP.plt','metric_CP_Random.plt']
	sw_files = []
	for e in sw_metric_files:
		temp_file = os.path.join(timestep_directory, e)
		sw_files.append(temp_file)
	if common_functions.list_intersection(sw_files, metric_files) != sw_files:
		err('Must have actual and random clustering coefficient and characteristic path length to calculate small world index!')
		return []
	else:
		sw_metrics = []
		for sw_file in sw_files:
			type = os.path.basename(sw_file)[7:9]  #  CC or (SP or CP)
			table = datalib.parse(sw_file)[type]
			try:
				data = table.getColumn('Mean').data
			except KeyError, x:
				# Maybe it's of an older format
				data = table.getColumn('Metric').data
			sw_metrics.append(data)	 # So sw_metrics = [CC,CC_Random,SP|CP,SP|CP_Random]

		g = __list_division(sw_metrics[0], sw_metrics[1])
		l = __list_division(sw_metrics[2], sw_metrics[3])
		s = __list_division(g, l)
		
		return s


####################################################################################
###
### FUNCTION compute_metrics()
###
####################################################################################
def compute_metrics(metrics,
					timestep_directory,
					tdata,
					random):
	global RandomN

	def __path(type):
		suffix = '_Random' if random else ''
		return os.path.join(timestep_directory, 'metric_' + type + suffix + '.plt')

	# --- Read in any metrics computed on a previous invocation of this script
	metrics_read = []
	for type in metrics:
		path = __path(type)

		if os.path.isfile(path):
			try:
				table = datalib.parse(path)[type]
				try:
					data = table.getColumn('Mean').data
				except KeyError, x:
					# Maybe it's of an older format
					data = table.getColumn('Metric').data
				tdata[type] = common_metric.normalize_metrics(data)

				metrics_read.append(type)
			except datalib.InvalidFileError, e:
				# file must have been incomplete
				print "Failed reading ", path, "(", e, ") ... regenerating"
		
	metrics_remaining = list_difference(metrics, metrics_read)
	
	print "	 AlreadyHave =", metrics_read
	print "	 MetricsToGet =", metrics_remaining

	# --- Compute metrics not already found on the file system
	if metrics_remaining:
		# --- Execute CalcMetric on all corresponding brainAnatomy files in anatomy dir
		brainFunction_files = glob.glob(os.path.join(timestep_directory, "brainFunction*.txt"))
		#Extract critter number from brainFunction files
		number_list = map(lambda x: int(os.path.basename(x)[14:-4]), brainFunction_files)
				
		anatomy_directory = os.path.join(timestep_directory, "..", "..", "anatomy")
		brainAnatomy_files_all = glob.glob(os.path.join(anatomy_directory, "*death.txt"))

		#Pick out those brainAnatomy files with corresponding critter number to brainFunction files.
		brainAnatomy_files = []
		for anatomyFile in brainAnatomy_files_all:
			if int(os.path.basename(anatomyFile)[13:-10]) in number_list:
				brainAnatomy_files.append(anatomyFile)
											   
		brainAnatomy_files.sort(lambda x, y: cmp(int(os.path.basename(x)[13:-10]),
							  int(os.path.basename(y)[13:-10])))
		if len(brainAnatomy_files) == 0:
			err('No brainanatomy files found in %s' % anatomy_directory)

		metrics_to_compute = metrics_remaining[:]
		if 'SW' in metrics_to_compute:
			compute_sw = True
			metrics_to_compute.remove('SW')
		else:
			compute_sw = False
		if 'SC' in metrics_to_compute:
			compute_sc = True
			metrics_to_compute.remove('SC')
		else:
			compute_sc = False
		if metrics_to_compute:  # computing something besides SW and SC		
			metric_all = calc_metrics(metrics_to_compute, brainAnatomy_files, random)
			if compute_sw:  # also need to compute SW (from the other metrics)
				sw = compute_small_world_index(timestep_directory, 'SP')
				i = 0
				for agent_results in metric_all:
					agent_results['metrics']['SW'] = [sw[i]]
					i += 1
			if compute_sc:  # also need to compute SW (from the other metrics)
				sw = compute_small_world_index(timestep_directory, 'CP')
				i = 0
				for agent_results in metric_all:
					agent_results['metrics']['SC'] = [sw[i]]
					i += 1
		elif compute_sw or compute_sc:  # computing just SW and/or SC (from the other metrics)
			if compute_sw:
				sw = compute_small_world_index(timestep_directory, 'SP')
			if compute_sc:
				sc = compute_small_world_index(timestep_directory, 'CP')
			metric_all = []
			i = 0
			for anatomy_file in brainAnatomy_files:
				agent = os.path.basename(anatomy_file)[13:-10]
				result = {}
				if compute_sw:
					result['SW'] = [sw[i]]
				if compute_sc:
					result['SC'] = [sc[i]]
				metric_all.append({'agent': agent, 'metrics': result})
				i += 1
		else:  # not computing anything (should never happen)
			metric_all = []

		colnames = ['AgentNumber', 'SampSize', 'Mean', 'StdDev']
		coltypes = ['int', 'int', 'float', 'float']

		tables = dict([(type, datalib.Table(type, colnames, coltypes))
				   for type in metrics_remaining])

		for agent_results in metric_all:
			agent = agent_results['agent']
			results = agent_results['metrics']

			for type in metrics_remaining:
				result = results[type]
	
				n = len(result)
				mean, stddev, stderr = algorithms.sample_mean( result )
			
				table = tables[type]
				row = table.createRow()

				row['AgentNumber'] = agent
				row['SampSize'] = n
				row['Mean'] = mean
				row['StdDev'] = stddev
	
		# --- Write to file and normalize data (eg sort and remove 0's)
		for type in metrics_remaining:
			table = tables[type]
	
			datalib.write(__path(type), table)
	
			data = table.getColumn('Mean').data
	
			tdata[type] = common_metric.normalize_metrics(data)

	return metrics


####################################################################################
###
### FUNCTION calc_metrics()
###
####################################################################################
def calc_metrics(metrics, anatomy_files, random):
	global RandomN
	metric_all = []
	
	for anatomy_file in anatomy_files:
		agent = os.path.basename(anatomy_file)[13:-10]
		result = dict([(metric, []) for metric in metrics])
	
		# Transform the anatomy file content into numpy adjacency matrix
		infile = open(anatomy_file,"r")
		lines = infile.readlines()
		lines.pop(0) # drop the header line

		H = []
		for i in range(len(lines)-1):  # -1 to leave out the bias unit
			l = lines[i].split()
			l.remove(';')
			g = []
			for j in range(len(l)-1):  # -1 to leave out the bias links
				g.append(abs(float(l[j])))
			H.append(g)
		B = numpy.matrix(H)

		#G_Dir = nx.from_numpy_matrix(B,nx.DiGraph())  # Geneterate directed version of brain network
		G_Undir = nx.from_numpy_matrix(B,nx.Graph())  # Generate undirected version of brain network
	
		N = RandomN if random else 1
		
		for i in range(N):
			if random:
				num_nodes = G_Undir.number_of_nodes()
				num_edges = G_Undir.number_of_edges()
				G = nx.gnm_random_graph(num_nodes,num_edges)
			else:
				G = G_Undir
		
			if 'CC' in metrics:
				# need to calculate average clustering coefficient
				avr_clustering = nx.average_clustering(G)
				result['CC'].append( avr_clustering )
	
			if 'SP' in metrics:
				# need to calculate normalized average shortest path length
				avr_shortest_path_length = nx.normalized_average_shortest_path_length(G,weighted=False)
				result['SP'].append( avr_shortest_path_length )						   

			if 'CP' in metrics:
				# need to calculate characteristic path length
				char_shortest_path_length = nx.average_shortest_path_length(G,weighted=False)
				result['CP'].append( char_shortest_path_length )
		
		metric_all.append({'agent': agent, 'metrics': result})
	
	return metric_all
						
			 
####################################################################################
###
### FUNCTION make_percents()
###
####################################################################################
def make_percents(tables, totals):
	for table in tables.values():
		for row in table.rows():
			t = row.get('Timestep')
			total = totals[t][table.name]

			for bin in range(NUMBINS):
				row.mutate(bin, lambda x: 100 * x / total)

####################################################################################
###
### FUNCTION compute_bins()
###
####################################################################################
def compute_bins(DATA, timesteps, complexities, AVR, minfunc, maxfunc):
	totals = dict([(t, {}) for t in timesteps])
	
	colnames = ['Timestep'] + [x for x in range(NUMBINS)]
	coltypes = ['int'] + ['int' for x in range(NUMBINS)]
	tables = {}
	
	for type in complexities:
		table_bins = datalib.Table(type, colnames, coltypes)
		tables[type] = table_bins
	
		table_avr = AVR[type]
	
		for row_avr in table_avr.rows():
			t = row_avr.get('Timestep')
			minimum = minfunc(row_avr)
			maximum = maxfunc(row_avr)
	
			row_bins = table_bins.createRow()
			row_bins.set('Timestep', t)
			for bin in range(NUMBINS): row_bins.set(bin, 0)
	
			data = DATA[t][type]
	
			totals[t][type] = 0
	
			if(maximum > minimum):
				for complexity in data:
					bin = int(((complexity - minimum)/(maximum - minimum))*NUMBINS)
					if bin >= NUMBINS:
						bin -= 1
					row_bins.mutate(bin, lambda x: x + 1)
	
					totals[t][type] += 1
	
	make_percents(tables, totals)

	return tables
			
####################################################################################
###
### FUNCTION show_usage()
###
####################################################################################
def show_usage(msg = None):
################################################################################
	print"""\
USAGE

  %s [<options>]... <directory>...

DESCRIPTION

     Analyzes the complexities of the epochs contained in one or more recent
  directories.

     <directory> can specify either a run directory or a parent of one or more
  run directories.

OPTIONS

     -D <dataset>
            Valid datasets:\
%s

            Note that datasets may be abbreviated.
            (default %s)

     -V <V>[,<V>]...
               Override default metrics, where V is one of:

               CC - Clustering Coefficient
               SP - (Normalized) Shortest Path length
               CP - Characteristic Path Length
               SW - Small World Index (based on SP)
               SC - Small World Index (based on CP)

            (default %s)""" % (sys.argv[0],
				   '\n				 '.join(['']+common_functions.RECENT_TYPES),
				   DefaultRecent,
				   ','.join(common_metric.DEFAULT_METRICS))

	if msg:
		print "--------------------------------------------------------------------------------"
		print
		print 'Error!', msg
	sys.exit(1)

####################################################################################
###
### Primary Code Path
###
####################################################################################

exit_value = main()

sys.exit(exit_value)
